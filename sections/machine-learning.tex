\section{Machine Learning}\label{sec:ai}
Content can be suggested in different ways.
Instead of only displaying content based on its publication date, it makes more sense to only suggest content that is relevant to the user.
But it is difficult to say what is relevant for a user and what is not, because in the end this should be decided by the user.
Because this is difficult to do by hand, this process should be supported by a machine learning algorithm.
A machine learning algorithm is basically an algorithm that can adapt results based on data inputs and thus learn more about results step by step.\\

Such an algorithm is also used by Twitter, for example\cite{twitter-deep-learning}.
Twitter itself even uses a subset of machine learning, namely deep learning.
Roughly speaking, even more information is processed here in different layers in the neural network.
In order to suggest posts, a lot of different data is collected in order to determine the relevance for the respective users.
There all interactions, previous interactions between user and post author or previous preferences are summarized and evaluated.\\

The difficult thing is that problems can arise in many places with such an approach.
Particular problem areas are the different machine learning steps: input, processing and output.
In order to keep these problems to a minimum, certain values are tracked, similar to value sensitive design.
These are fairness, accountability, transparency and ethics.
First, it is difficult to ensure all these values perfectly.
Similar to value sensitive design, however, it is better to think about such values than to ignore them completely.\\

Fairness can be ensured if students are interviewed from as many categories as possible.
In doing so, prejudices should be eliminated and all categories of students should be treated equally\cite{fairness-framework}.
This could be characterized by the fact that people who insult on the platform UK4You both are punished equally for the same insult.
On the other hand, it should also be noted that people with disadvantages are also taken into account.
Insults that occur as a tic due to Tourette's neuropsychiatric illness cannot be punished in the same way as deliberate active insults.\\

Basically, making machine learning accountable means that you have to consider what effects can arise from the use of machine learning and who is accountable for it.
It should be noted that machine learning always takes place within the legal framework and does not violate any legal guidelines.
The important thing about accountability is that a team of experts can initiate measures in the event of problems.
For example, let's assume that an algorithm ensures that a person is constantly shown objectionable content on the UK4You platform.
Despite setting different filters, it is not possible to get rid of them.
However, the person could not continue to use the platform because this content triggers the user in some way.
The logical consequence of this would be that a team of experts can intervene in this algorithm in order to filter the content.
Thus, the user would no longer be excluded from the platform by the triggering content.\\

Another point is to make processes transparent. 
This applies not only to users, but also to designers or other stakeholders.
Let's take the example from earlier where the expert team wants to filter content.
When the algorithm works as a black box where only input and output are known, no easy adjustments can be made.
However, if the algorithm were transparent, developers could easily locate the problem area.
But transparency is also important for users. 
Suggesting content to users without conveying what it is based on means that users are less able to determine what they consume.
If every interaction can trigger certain processes inside a black box, this ensures that users unconsciously determine their own content without possibly wanting to.
It is also unclear which interaction is responsible for a change at all.
For this reason, this should be communicated clearly. 
The algorithm should be made explainable.\\

UK4You should be a platform that meets current ethical standards.
Therefore, before using the UK4You platform, the ethical committee of the University of Kassel should be considered.
It is also necessary to consider which data is used for the learning process.
As already mentioned, there are three central points in the learning process.
And it is precisely in these three problem areas that different forms of bias can occur\cite{framework-understanding-ml}.\\

% TODO: all different bias

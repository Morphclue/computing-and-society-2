\section{Machine Learning}\label{sec:ai}
Content can be suggested in different ways.
Instead of only displaying content based on its publication date, it makes more sense to only suggest content that is relevant to the user.
But it is difficult to say what is relevant for a user and what is not, because in the end this should be decided by the user.
Because this is difficult to do by hand, this process should be supported by a machine learning algorithm.
A machine learning algorithm is basically an algorithm that can adapt results based on data inputs and thus learn more about results step by step.\\

Such an algorithm is also used by Twitter, for example\cite{twitter-deep-learning}.
Twitter itself even uses a subset of machine learning, namely deep learning.
Roughly speaking, even more information is processed here in different layers in the neural network.
In order to suggest posts, a lot of different data is collected in order to determine the relevance for the respective users.
There all interactions, previous interactions between user and post author or previous preferences are summarized and evaluated.\\

The difficult thing is that problems can arise in many places with such an approach.
Particular problem areas are the different machine learning steps: input, processing and output.


% With the help of AI, it would be possible to ensure the filtering of certain content.


\textcolor{red}{TODO: there is still a lot of stuff that has to be done here}

\subsection{Concerns}
Fairness (no prejudice and should be treated the same)
\begin{itemize}
    \item Gender
    \item Students from abroad
\end{itemize}

Accountability:
\begin{itemize}
    \item Legal
    \item Reasons for effects through explainability
\end{itemize}

Transparency:
\begin{itemize}
    \item Make AI explainable
    \item Interpretable
\end{itemize}


With the help of visualization tools, checklists etc. (provided in "A Framework for Fairness") and the Data Nutrition Project.

